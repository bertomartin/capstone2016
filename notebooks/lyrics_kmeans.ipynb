{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pymongo import  MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)\n",
    "db = client.lyrics\n",
    "coll = db.yearly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>title</th>\n",
       "      <th>track_id</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5827dca77aa2eb0ad91b8fdc</td>\n",
       "      <td>Bukka White</td>\n",
       "      <td>I was over in Aberdeen\\nOn my way to New Orlea...</td>\n",
       "      <td>Aberdeen Mississippi Blues</td>\n",
       "      <td>TRHRKYP128F4280BB1</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5827dca77aa2eb0ad91b8fdd</td>\n",
       "      <td>Bukka White</td>\n",
       "      <td>When a man gets trouble in his mind\\nHe wanna ...</td>\n",
       "      <td>Sleepy Man Blues</td>\n",
       "      <td>TRCAHZD128F4280BC1</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5827dca77aa2eb0ad91b8fde</td>\n",
       "      <td>Bessie Smith</td>\n",
       "      <td>Woke up this mornin' when chickens was crowin'...</td>\n",
       "      <td>Young Woman's Blues</td>\n",
       "      <td>TRJBDVE128F9306FDB</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5827dca77aa2eb0ad91b8fdf</td>\n",
       "      <td>Bukka White</td>\n",
       "      <td>I'm taken down with the fever and it won't let...</td>\n",
       "      <td>High Fever Blues</td>\n",
       "      <td>TRRRGCS128F4280BB6</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5827dca77aa2eb0ad91b8fe2</td>\n",
       "      <td>Bukka White</td>\n",
       "      <td>Hey-eee, come on you women\\nLet's a do the the...</td>\n",
       "      <td>Bukka's Jitterbug Swing</td>\n",
       "      <td>TRXZHEC128F4280BB2</td>\n",
       "      <td>1940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id        artist  \\\n",
       "0  5827dca77aa2eb0ad91b8fdc   Bukka White   \n",
       "1  5827dca77aa2eb0ad91b8fdd   Bukka White   \n",
       "2  5827dca77aa2eb0ad91b8fde  Bessie Smith   \n",
       "3  5827dca77aa2eb0ad91b8fdf   Bukka White   \n",
       "4  5827dca77aa2eb0ad91b8fe2   Bukka White   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  I was over in Aberdeen\\nOn my way to New Orlea...   \n",
       "1  When a man gets trouble in his mind\\nHe wanna ...   \n",
       "2  Woke up this mornin' when chickens was crowin'...   \n",
       "3  I'm taken down with the fever and it won't let...   \n",
       "4  Hey-eee, come on you women\\nLet's a do the the...   \n",
       "\n",
       "                        title            track_id  year  \n",
       "0  Aberdeen Mississippi Blues  TRHRKYP128F4280BB1  1940  \n",
       "1            Sleepy Man Blues  TRCAHZD128F4280BC1  1940  \n",
       "2         Young Woman's Blues  TRJBDVE128F9306FDB  1940  \n",
       "3            High Fever Blues  TRRRGCS128F4280BB6  1940  \n",
       "4     Bukka's Jitterbug Swing  TRXZHEC128F4280BB2  1940  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data from mongodb into pandas\n",
    "data = coll.find()\n",
    "song_lyrics = pd.DataFrame(list(data))\n",
    "song_lyrics.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### pre-processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# nltk processing\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.stem\n",
    "from string import punctuation\n",
    "import re\n",
    "def lyric_preprocessor(lyric, stem=False):\n",
    "    stop_words = set(stopwords.words('english') + list(punctuation))\n",
    "    re_replace = {\n",
    "        r\"\\bdon't\\b\": \"do not\",\n",
    "        r\"\\bdoesn't\\b\": \"does not\",\n",
    "        r\"\\bdidn't\\b\": \"did not\",\n",
    "        r\"\\bhasn't\\b\": \"has not\",\n",
    "        r\"\\bhaven't\\b\": \"have not\",\n",
    "        r\"\\bhadn't\\b\": \"had not\",\n",
    "        r\"\\bwon't\\b\": \"will not\",\n",
    "        r\"\\bwouldn't\\b\": \"would not\",\n",
    "        r\"\\bcan't\\b\": \"can not\",\n",
    "        r\"\\bcannot\\b\": \"can not\",\n",
    "        r\"\\bain't\\b\": \"is not\"\n",
    "    }\n",
    "    \n",
    "    lyric = lyric.lower()\n",
    "    for r, replacement in re_replace.items():\n",
    "        lyric = re.sub(r, replacement, lyric)\n",
    "        \n",
    "    lyric_words = word_tokenize(lyric)\n",
    "    lyric_words_clean = [word for word in lyric_words if word not in stop_words]\n",
    "    if stem:\n",
    "        stemmer = nltk.stem.SnowballStemmer('english')\n",
    "        return [stemmer.stem(word) for word in lyric_words_clean]\n",
    "    \n",
    "    # not stemmed\n",
    "    return lyric_words_clean\n",
    "\n",
    "\n",
    "# build a scikit-learn transformer so things play nicely with sklearn\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class LyricPreprocessor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, stop_words=None, lower=True, strip=True):\n",
    "        self.lower = lower\n",
    "        self.strip = strip\n",
    "        self.stopwords = stop_words or set(stopwords.words('english') + list(punctuation))\n",
    "        self.stemmer = nltk.stem.SnowballStemmer('english')\n",
    "        self.re_replace = {\n",
    "            r\"\\bdon't\\b\": \"do not\",\n",
    "            r\"\\bdoesn't\\b\": \"does not\",\n",
    "            r\"\\bdidn't\\b\": \"did not\",\n",
    "            r\"\\bhasn't\\b\": \"has not\",\n",
    "            r\"\\bhaven't\\b\": \"have not\",\n",
    "            r\"\\bhadn't\\b\": \"had not\",\n",
    "            r\"\\bwon't\\b\": \"will not\",\n",
    "            r\"\\bwouldn't\\b\": \"would not\",\n",
    "            r\"\\bcan't\\b\": \"can not\",\n",
    "            r\"\\bcannot\\b\": \"can not\",\n",
    "            r\"\\bain't\\b\": \"is not\"\n",
    "            }\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def inverse_transform(self, X):\n",
    "        return [\" \".join(doc) for doc in X]\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [\n",
    "            list(self.pre_process(doc)) for doc in X\n",
    "            ]\n",
    "        \n",
    "    def pre_process(self, lyric):\n",
    "        # replacements\n",
    "        for r, replacement in self.re_replace.items():\n",
    "            lyric = re.sub(r, replacement, lyric)\n",
    "        \n",
    "        for token in word_tokenize(lyric):\n",
    "            token = token.lower() if self.lower else token\n",
    "            token = token.strip() if self.strip else token\n",
    "            if token in self.stopwords:\n",
    "                continue\n",
    "                \n",
    "            stemmed_token = self.stemmer.stem(token)\n",
    "            yield stemmed_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "docs = song_lyrics['lyrics'] # a series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "processed_lyric = lyric_preprocessor(docs[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "def identity(arg):\n",
    "    \"\"\"\n",
    "    Simple identity function works as a passthrough.\n",
    "    \"\"\"\n",
    "    return arg\n",
    "vectorizer = Pipeline([\n",
    "        ('preprocessor', LyricPreprocessor()),\n",
    "        ('vectorizer', TfidfVectorizer(\n",
    "            tokenizer = identity, preprocessor=None, lowercase=False))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature extraction (vectorization)\n",
    "lyric_vec = vectorizer.fit_transform(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<12664x54829 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 742245 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "lyric_vec # 54k features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial model\n",
    "from sklearn.cluster import KMeans\n",
    "km = KMeans(n_clusters = 10, init = 'k-means++', max_iter=100, n_init=1, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization complete\n",
      "Iteration  0, inertia 22558.591\n",
      "Iteration  1, inertia 12058.019\n",
      "Iteration  2, inertia 11998.160\n",
      "Iteration  3, inertia 11969.858\n",
      "Iteration  4, inertia 11957.127\n",
      "Iteration  5, inertia 11949.572\n",
      "Iteration  6, inertia 11944.732\n",
      "Iteration  7, inertia 11941.894\n",
      "Iteration  8, inertia 11939.977\n",
      "Iteration  9, inertia 11937.260\n",
      "Iteration 10, inertia 11934.707\n",
      "Iteration 11, inertia 11932.411\n",
      "Iteration 12, inertia 11930.304\n",
      "Iteration 13, inertia 11928.741\n",
      "Iteration 14, inertia 11927.388\n",
      "Iteration 15, inertia 11926.279\n",
      "Iteration 16, inertia 11924.990\n",
      "Iteration 17, inertia 11923.009\n",
      "Iteration 18, inertia 11919.705\n",
      "Iteration 19, inertia 11916.276\n",
      "Iteration 20, inertia 11915.106\n",
      "Iteration 21, inertia 11914.586\n",
      "Iteration 22, inertia 11914.210\n",
      "Iteration 23, inertia 11913.987\n",
      "Iteration 24, inertia 11913.803\n",
      "Iteration 25, inertia 11913.653\n",
      "Iteration 26, inertia 11913.547\n",
      "Iteration 27, inertia 11913.457\n",
      "Iteration 28, inertia 11913.340\n",
      "Iteration 29, inertia 11913.285\n",
      "Iteration 30, inertia 11913.251\n",
      "Iteration 31, inertia 11913.214\n",
      "Iteration 32, inertia 11913.194\n",
      "Iteration 33, inertia 11913.178\n",
      "Iteration 34, inertia 11913.168\n",
      "Iteration 35, inertia 11913.165\n",
      "Iteration 36, inertia 11913.161\n",
      "Converged at iteration 36\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KMeans(copy_x=True, init='k-means++', max_iter=100, n_clusters=10, n_init=1,\n",
       "    n_jobs=1, precompute_distances='auto', random_state=None, tol=0.0001,\n",
       "    verbose=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate cluster\n",
    "km.fit(lyric_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32),\n",
       " array([2088,  317, 1567,  787, 3899,  839,  251,  492, 1859,  565]))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.unique(km.labels_, return_counts=True) # get number of articles in each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text = {}\n",
    "for i, cluster in enumerate(km.labels_):\n",
    "    doc = docs[i]\n",
    "    if cluster not in text.keys():\n",
    "        text[cluster] = doc\n",
    "    else:\n",
    "        text[cluster] += doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## analyze words from each cluster (topics)\n",
    "from nltk.probability import FreqDist\n",
    "from collections import defaultdict\n",
    "from heapq import nlargest\n",
    "\n",
    "keywords = {}\n",
    "counts = {}\n",
    "for cluster in range(10):\n",
    "    word_sent = word_tokenize(text[cluster].lower())\n",
    "    word_sent = [word for word in word_sent]\n",
    "    freq = FreqDist(word_sent)\n",
    "    keywords[cluster] = nlargest(100, freq, key=freq.get)\n",
    "    counts[cluster] = freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### get unique keywords from each cluster\n",
    "unique_keys = {}\n",
    "for cluster in range(10):\n",
    "    other = list(set(range(20)) - set([cluster]))\n",
    "    keys_other = set(keywords[other[0]]).union(set(keywords[other[1]]))\n",
    "    unique = set(keywords[cluster]) - keys_other\n",
    "    unique_keys[cluster] = nlargest(20, unique, key=counts[cluster].get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['away',\n",
       "  'night',\n",
       "  'day',\n",
       "  'eyes',\n",
       "  'through',\n",
       "  'our',\n",
       "  'dream',\n",
       "  'heart',\n",
       "  'us',\n",
       "  'light',\n",
       "  'hear',\n",
       "  'would',\n",
       "  'only',\n",
       "  'again',\n",
       "  'feel'],\n",
       " 1: [\"''\", '``', 'said', 'had', 'then', 'him', \"'d\", 'did', ':'],\n",
       " 2: ['right', 'good', 'make', 'too', 'ta', 'girl', \"'cause\", 'or', 'baby'],\n",
       " 3: ['la',\n",
       "  'de',\n",
       "  'que',\n",
       "  'un',\n",
       "  'y',\n",
       "  'e',\n",
       "  'en',\n",
       "  'el',\n",
       "  'tu',\n",
       "  'se',\n",
       "  'le',\n",
       "  'che',\n",
       "  'te',\n",
       "  'il',\n",
       "  'les',\n",
       "  'et',\n",
       "  'mi',\n",
       "  'non',\n",
       "  'je',\n",
       "  'di'],\n",
       " 4: ['baby',\n",
       "  'little',\n",
       "  'hey',\n",
       "  'want',\n",
       "  'make',\n",
       "  'right',\n",
       "  'girl',\n",
       "  'da',\n",
       "  'too',\n",
       "  'gon',\n",
       "  '-'],\n",
       " 5: ['baby',\n",
       "  'want',\n",
       "  'need',\n",
       "  'give',\n",
       "  'why',\n",
       "  'make',\n",
       "  'more',\n",
       "  'girl',\n",
       "  'ever',\n",
       "  'been',\n",
       "  'loving'],\n",
       " 6: ['long',\n",
       "  'been',\n",
       "  'gone',\n",
       "  'too',\n",
       "  'baby',\n",
       "  'gon',\n",
       "  'home',\n",
       "  'wrong',\n",
       "  'wo',\n",
       "  'lord',\n",
       "  'alone',\n",
       "  'make'],\n",
       " 7: ['baby',\n",
       "  'want',\n",
       "  'girl',\n",
       "  'good',\n",
       "  'right',\n",
       "  'need',\n",
       "  'hey',\n",
       "  'make',\n",
       "  'gon',\n",
       "  'been',\n",
       "  'give',\n",
       "  'please',\n",
       "  'little',\n",
       "  'wo',\n",
       "  'wan',\n",
       "  \"'cause\"],\n",
       " 8: ['want',\n",
       "  'make',\n",
       "  'need',\n",
       "  'think',\n",
       "  'been',\n",
       "  'more',\n",
       "  'why',\n",
       "  'give',\n",
       "  'good',\n",
       "  'right'],\n",
       " 9: ['gon',\n",
       "  'wan',\n",
       "  'baby',\n",
       "  'rock',\n",
       "  'make',\n",
       "  'tonight',\n",
       "  'want',\n",
       "  'right',\n",
       "  'girl',\n",
       "  'good',\n",
       "  'around',\n",
       "  \"'cause\",\n",
       "  'more']}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a classifier for new lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I was over in Aberdeen\n",
      "On my way to New Orlean\n",
      "I was over in Aberdeen\n",
      "On my way to New Orlean\n",
      "Them Aberdeen women told me\n",
      "Will buy my gasoline\n",
      "\n",
      "Hey, two little women\n",
      "That I ain't ever seen\n",
      "They has two little women\n",
      "That I ain't never seen\n",
      "These two little women\n",
      "Just from New Orlean\n",
      "\n",
      "Ooh, sittin' down in Aberdeen\n",
      "With New Orlean on my mind\n",
      "I'm sittin' down in Aberdeen\n",
      "With New Orlean on my mind\n",
      "Well, I believe them Aberdeen women\n",
      "Gonna make me lose my mind, yeah\n",
      "\n",
      "Aber-deen is my home\n",
      "But the mens don't want me around\n",
      "Aberdeen is my home\n",
      "But the men don't want me around\n",
      "They know I will take these women\n",
      "An take them outta town\n",
      "\n",
      "Listen, you Aberdeen women\n",
      "You know I ain't got no dime\n",
      "Oh-oh listen you women\n",
      "You know'd I ain't got no dime\n",
      "They been had the po' boy\n",
      "All up and down\n"
     ]
    }
   ],
   "source": [
    "# build a classifier using KNN\n",
    "new_lyric = docs[0]\n",
    "print(new_lyric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x54829 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 41 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lyric_vector = vectorizer.transform([new_lyric])\n",
    "new_lyric_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "classifier.fit(lyric_vec, km.labels_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_lyric_label = classifier.predict(new_lyric_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4], dtype=int32)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_lyric_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "similar_indx = (km.labels_==new_lyric_label).nonzero()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3899"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(similar_indx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3899\n"
     ]
    }
   ],
   "source": [
    "import scipy as sp\n",
    "recommendations = []\n",
    "for i in similar_indx:\n",
    "    dist = sp.linalg.norm((new_lyric_vector - lyric_vec[i]).toarray())\n",
    "    recommendations.append((dist, docs[i]))\n",
    "recommendations = sorted(recommendations)\n",
    "print(len(recommendations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2.9897696156037272e-16, \"I was over in Aberdeen\\nOn my way to New Orlean\\nI was over in Aberdeen\\nOn my way to New Orlean\\nThem Aberdeen women told me\\nWill buy my gasoline\\n\\nHey, two little women\\nThat I ain't ever seen\\nThey has two little women\\nThat I ain't never seen\\nThese two little women\\nJust from New Orlean\\n\\nOoh, sittin' down in Aberdeen\\nWith New Orlean on my mind\\nI'm sittin' down in Aberdeen\\nWith New Orlean on my mind\\nWell, I believe them Aberdeen women\\nGonna make me lose my mind, yeah\\n\\nAber-deen is my home\\nBut the mens don't want me around\\nAberdeen is my home\\nBut the men don't want me around\\nThey know I will take these women\\nAn take them outta town\\n\\nListen, you Aberdeen women\\nYou know I ain't got no dime\\nOh-oh listen you women\\nYou know'd I ain't got no dime\\nThey been had the po' boy\\nAll up and down\")\n"
     ]
    }
   ],
   "source": [
    "print(recommendations[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.1986508173334078, \"It's time I'm walkin' to New Orleans\\nI'm walkin' to New Orleans\\nI'm going to need two pair of shoes\\nWhen I get through walkin' these blues\\nWhen I get back to New Orleans\\n\\nI've got my suitcase in my hand\\nNow, ain't that a shame\\nI'm leavin' here today\\nYes, I'm goin' back home to stay\\nYes, I'm walkin' to New Orleans\\n\\nYou used to be my honey\\nTill you spent all my money\\nNo use for you to cry\\nI'll see you bye and bye\\nCause I'm walkin' to New Orleans\\n\\nI've got no time for talkin'\\nI've got to keep on walkin'\\nNew Orleans is my home\\nThat's the reason why I'm goin'\\nYes, I'm walkin' to New Orleans\\n\\nI'm walkin' to New Orleans\\nI'm walkin' to New Orleans\\nI'm walkin' to New Orleans\")\n"
     ]
    }
   ],
   "source": [
    "print(recommendations[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.4142135623730956, 'Yaralı dizlerim koşamam ki\\nKapalı yollarından alkamam ki\\nUnutkan nehrimin \\nYolumu sormadan bulamam ki\\nKarlı dağlarında doğamam ki\\nSaklı kentinin\\n\\nÇok üzülme, çok susma\\n  Çok terleme, çok susma\\n  Çok da kitap okuma     dedi annem\\n \\nÇok terleme çok yorulma\\n  Girdaplarında boğulma\\n  Yalnızlığına da çok alışma\\n\\nGüneşim olmaden göremem ki\\nAy tutulurken uyuyamam ki\\nKaranlık olsa da\\nBen herkesi sevemem ki\\nSevmeden de yaşayamam ki\\nYanlış olsa da')\n"
     ]
    }
   ],
   "source": [
    "print(recommendations[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
